# A Survey on Large Language Models for Recommendation

https://github.com/WLiK/LLM4Rec-Awesome-Papers?tab=readme-ov-file

https://arxiv.org/pdf/2305.19860

## Abstract

- LLM 모델의 힘을 활용하여 추천 품질을 향상 중요 포인트
    - 이들의 고품질 텍스트 특징에 대한 표현과 외부 지식의 광범위한 커버리지를 이용 → 아이템과 사용자 간의 상관관계를 구축하는 것
- 각각 판별적(discriminative)과 생성적(generative)이라는 두 가지 주요 패러다임으로 분류
    - DLLM4Rec / GLLM4Rec
    - GLLM4Rec 는 이 논문에서 처음으로 체계적 정리됨
- 기존 LLM 기반 추천 시스템을 체계적으로 검토하고 분석하여 이들의 방법론, 기술, 성능에 대한 통찰

## 1. Introduction

- LLM을 추천 시스템에 통합하는 주요 장점은 텍스트 특징의 고품질 표현을 추출하고 그 안에 인코딩된 방대한 외부 지식을 활용할 수 있는 능력
    - 전통적인 추천 시스템과 달리 LLM 기반 모델은 맥락 정보를 캡처하고 사용자 쿼리, 항목 설명 및 기타 텍스트 데이터를 보다 효과적으로 이해
    - 기존 추천시스템 분야에서는 일반적인 데이터 희소성 문제에 직면, LLM은 제로/적은 샷 추천 능력을 통해 추천 시스템에 새로운 가능성
- 판별적(discriminative) 모델은 많이 적용되는 편
    - 생성 언어 모델:
        - 원래는 관심 크지 않았는데 LLM 등장으로,
        - 데이터 희소성과 효율성 문제를 해결하기 위한 언어 모델링 패러다임의 적응이 학계와 산업 모두에서 주목 받는중
    - 다양한 도메인 간 지식 전이 방법 related works
        - 주로 사전 훈련 언어 모델의 훈련 기법 및 전략의 전이에 초점
        - 언어 모델의 잠재력과 그 능력, 즉 LLM 기반 방식은 탐구 X

![image](https://github.com/user-attachments/assets/ae115c3f-1029-4311-84c3-89cfc70eb440)

- 기여점
    - 대규모 언어 모델 추천 시스템을 세 가지 뚜렷한 모델링 패러다임으로 분류
    - 기존 방법들의 장점, 단점, 한계에 대한 비판적 분석을 수행
        
        

## 2. Modeling Paradigms and Taxonomy

- 추천 시스템을 위한 대형 언어 모델 연구의 세 가지 주요 범주
    - **LLM 임베딩 + 추천 시스템:**
        - 언어 모델을 특징 추출기로 보고,
        - 아이템과 사용자에 대한 특징을 LLM에 입력하여 해당하는 임베딩을 출력
    - **LLM 토큰 + 추천 시스템:**
        - (전자랑 유사) 입력된 아이템 및 사용자 특징을 기반으로 토큰을 생성
        - 생성된 토큰은 의미적 마이닝을 통해 잠재적인 선호를 포착
    - **LLM을 추천 시스템으로 사용:**
        - 사전 훈련된 LLM을 강력한 추천 시스템으로 직접 전이하는 것을 목표
        - 입력 시퀀스는 일반적으로 프로필 설명, 행동 프롬프트, 작업 지침으로 구성
        - 출력 시퀀스는 합리적인 추천 결과를 제공하는 것을 기대

- 기존 작업을 각각 판별적 LLM과 생성적 LLM으로 두 가지 주요 범주로 분류
    - 판별적 언어 모델은 패러다임 (1) 내에서 잘 적합
    - 생성적 대형 언어 모델의 응답 생성 능력은 패러다임 (2) 또는 (3)을 더욱 지원

![image 1](https://github.com/user-attachments/assets/e7876f27-89a1-43cc-95a3-6cc59c9c770f)

## 3. Discriminative LLMs for Recommendation

- Discriminative (판별적, 구별적) 언어 모델: BERT 계열 모델 지칭
    - 자연어 이해 작업 능력 → 다양한 다운스트림 작업을 위한 임베딩 백본으로 자주 고려

![image 2](https://github.com/user-attachments/assets/1ad29b18-ba11-4c79-aa2f-fdd609f93bc8)

### 3.1 Fine-tuning

- 미세 조정의 아이디어: 사전 학습된 언어 모델을 특정 작업 또는 도메인에 적응시키기 위해 작업별 데이터로 추가 훈련
- 미세 조정 과정: 사전 훈련된 언어 모델을 학습된 파라미터로 초기화한 후 추천 특정 데이터 세트에서 훈련하는 것을 포함
    - 이 데이터 세트는 일반적으로 사용자-아이템 상호작용, 아이템의 텍스트 설명, 사용자 프로필 및 기타 관련 맥락 정보 포함
- 대부분 BERT 를 이용한 추천시스템은 미세조정 방법을 사용함
    - 연구1) 사용자-베이스(U-BERT): 리뷰 간의 암묵적 의미 상호작용을 포착하기 위해 리뷰 공동 매칭 레이어가 설계
    - 연구2) UserBERT: 사용자 모델 사전 훈련을 위해 두 가지 self supervision 작업이 unlabeled 행동 데이터에 통합되어 사용자 모델링을 강화
- 사전 훈련된 BERT는 순위 작업에서도 뛰어난 성과
    - 연구1) BECR: 깊은 맥락 토큰 상호작용과 전통적인 어휘 용어 일치 기능을 동시에 결합한 경량 복합 재순위 방법을 제안
    - 연구2) 도메인 특화된 BERT: 제품 순위 지정을 위한 엔드 투 엔드 다중 작업 학습 프레임워크를 제안하여 쿼리와 제품 간의 어휘 불일치 문제를 해결
    - 데이터 활용을 위해 전문가 혼합 레이어와 작업 간 확률 전이를 사용
- 그룹 추천, 검색/매칭, CTR 예측 등 다른 특정 작업이나 시나리오에 대한 많은 관련 연구
    - 여러 연속 또는 세션 기반 추천 시스템에서 중요한 역할
    - 훈련 전략의 이점을 활용 → 본 논문의 초점 X
    - 연구1) UniSRec: 아이템의 설명 텍스트를 연관 지어 다양한 추천 시나리오에서 전이 가능한 표현을 학습
    - 연구2) Hou et al [27]: 전이 가능한 순차 추천을 위한 구별 가능한 벡터 양자화 아이템 코드를 학습하는 방안을 제안
    - 등등
    - 연구n) 순수한 모달리티 기반 추천 모델(MoRec): 아이템 ID 임베딩을 최첨단 모달리티 인코더로 교체, 순수 ID 기반 모델(IDRec) 보다 우수한지 테스트.
- 요약: BERT 미세 조정의 추천 시스템에의 통합은 강력한 외부 지식과 개인화된 사용자 선호를 융합하여 주로 추천 정확도를 높이고 동시에 제한된 역사적 데이터를 가진 새로운 아이템에 대한 작은 콜드 스타트 처리 능력을 갖추는 것을 목표

### 3.2 프롬프트 튜닝

- 하드/소프트 프롬프트와 레이블 단어 언어화를 사용
    - 그림 5 (b)처럼, DLLM에서 일반적으로 사용되는 마스크 기반 훈련으로 인해 언급된 언어화의 역할은 [MASK] 위치에서 DLLM에 의해 예측된 단어와 실제 레이블 간의 매핑을 설정하는 것

![image 2](https://github.com/user-attachments/assets/1ad29b18-ba11-4c79-aa2f-fdd609f93bc8)

- 연구1) [35]:
    - BERT의 마스크 언어 모델링(MLM) 헤드를 활용하여 클로즈 스타일 프롬프트를 사용아이템 장르에 대한 이해
    - BERT의 다음 문장 예측(NSP) 헤드와 표현의 유사성(SIM)을 활용하여 관련 및 비관련 검색과 추천 쿼리-문서 입력을 비교
    - →  BERT는 미세 조정 없이도 순위 결정 과정에서 관련 아이템을 우선적으로 처리
- 연구2) [36]:
    - 프롬프트와 함께 대화형 추천 시스템을 개발
    - BERT 기반 아이템 인코더는 각 아이템의 메타데이터를 임베딩에 직접 매핑
- 연구3) [37]:
    - 사용자-아이템 속성 공정성 분석을 통합한 대화형 추천 시스템을 개발
    - 템플릿 기반 결과 생성
    - 템플릿에는 이름이나 관계와 같은 비선호적 정보가 포함되어 있어 인종, 성별, 성적 지향, 지리적 맥락 및 종교와 같은 특성을 암묵적 나타낼 수 있음
- 연구4) Prompt4NR:
    - 뉴스 추천을 위한 프롬프트 학습 패러다임의 적용
    - 후보 뉴스에 대한 사용자의 클릭을 예측하는 목표를 클로즈 스타일의 마스크 예측 과제로 재정의
    - 추천 시스템의 성능은 다중 프롬프트 앙상블을 활용함으로써 유의미하게 향상

## 4. Generative LLMs for Recommendation

- 생성적 모델은 자연어 생성 능력이 더 좋다
    - LLM이 학습한 표현을 추천 도메인에 맞추는 대부분의 Discriminative 모델 기반 접근 방식과 달리
    - 대부분의 생성적인 모델 기반 작업은 추천 작업을 자연어 작업으로 변환한 후 맥락 내 학습, 프롬프트 조정 및 지침 조정과 같은 기술을 적용하여 LLM이 직접 추천 결과를 생성하도록 적응

![image 3](https://github.com/user-attachments/assets/8af7b238-c9f9-4f06-829a-190b41ca6347)

### 4.1 Non-tuning Paradigm

- LM이 이미 추천 능력을 가지고 있다고 가정, 특정 프롬프트를 도입하여 활용
- 추천 작업에 LLM을 적응시키기 위해 최근의 Prompting과 In-context Learning을 채택

**4.1.1 Prompting**

- LLM이 추천 작업을 더 잘 이해하고 해결하도록 돕기 위해 더 적합한 지침과 프롬프트를 설계하는 것을 목표
- ChatGPT가 다섯 가지 일반 추천 작업인 평가 예측, 순차 추천, 직접 추천, 설명 생성 및 리뷰 요약에 대한 성능을 체계적으로 평가
- 구성 요소
    - **작업 설명(Task Description):** 추천 작업을 자연어 처리 작업으로 조정.
    - **행동(Behavior):** 사용자와 아이템 간의 상호작용을 포함하여 LLM이 사용자 선호와 요구를 더 잘 이해하도록 돕는 방식.
    - **형식 표시자(Format Indicator):** 출력 형식을 제어하여 결과를 보다 명확하고 평가 가능하게 만듦.
- **Related works**
    - 연구1) 다양한 종류의 작업을 위해 다른 프롬프트를 제안하고, ChatGPT의 도메인 적응 능력을 향상시키기 위해 프롬프트 시작 부분에 역할 지시문(예: 당신은 이제 뉴스 추천 시스템입니다.)을 도입
        - ChatGPT의 추천 능력에 대한 실증 분석을 세 가지 일반 정보 검색 작업(점 기반, 쌍 기반, 목록 기반 순위 포함)에서 수행
        
        <aside>
        💡
        
        **정보 검색 작업**
        
        ### **Point-wise (포인트 와이즈)**
        
        - **의미:** 개별 데이터 포인트(예: 한 개의 사용자-아이템 쌍)를 독립적으로 처리하는 방식입니다.
        - **예시:** "사용자가 이 영화를 얼마나 좋아할까?"라는 질문에 대해 점수(별점이나 확률)를 예측.
        - **사용 사례:** 사용자-아이템 간의 점수 예측, 회귀 문제로 처리.
        
        ### **Pair-wise (페어 와이즈)**
        
        - **의미:** 두 데이터 포인트를 비교하여 어떤 것이 더 적합한지 예측하는 방식입니다.
        - **예시:** "사용자는 영화 A를 영화 B보다 더 좋아할까?"라는 질문에 답하도록 학습.
        - **사용 사례:** 순위 비교, 특정 사용자가 여러 옵션 중 무엇을 더 선호하는지 판단.
        
        ### **List-wise (리스트 와이즈)**
        
        - **의미:** 데이터 포인트가 리스트(목록) 단위로 제공되며, 전체 리스트의 순위를 조정하거나 최적화하는 방식입니다.
        - **예시:** "이 사용자를 위해 추천 목록을 어떻게 정렬할까?"라는 질문에 답함.
        - **사용 사례:** 검색 결과나 추천 목록의 순위 최적화.
        </aside>
        
    
    - 연구2) 복구 메커니즘 및 피드백 메커니즘과 같은 열 가지 기본 원칙의 관점에서 대형 언어 모델(LLMs)을 사용하여 인공지능 일반 추천 시스템(AGR)을 개발
    - 연구3) 항목만 있는 경우(항목의 속성), 언어만 있는 경우(사용자 선호의 설명), 그리고 실험에서 결합된 언어+항목을 위한 세 가지 프롬프트 템플릿을 설계
        
        → 콜드스타트 시나이로에서 항목 기반 협업 필터링 방법과 비교할 때 놀라울 정도로 경쟁력을 입증
        
    - 연구4) MINT [45]: 사용자 상호작용 데이터를 기반으로 프롬프트로 사용자의 의도를 요약
    - 연구5) KAR [46]: 사용자 선호와 사실적 지식에 대한 정확한 추론을 유도하기 위해 분해된 프롬프트를 도입
    
- **일반적인 프레임워크를 제안하기보다는 특정 추천 작업을 위한 효과적인 프롬프트 설계에 중점을 두는 일부 연구 존재**
    - 연구1) LLM에 허용된 입력 토큰의 수 제한 → 슬라이딩 윈도우 프롬프트 전략을 제안, 매번 윈도우의 후보만 순위를 매기고, 윈도우를 처음으로 되돌려 슬라이드한 후 이 과정을 여러 번 반복하여 전체 순위 결과 산출
    - 연구2) LLM을 사용하여 전통적 순차 추천기의 해석 가능성을 향상시키기 위한 시퀀스 잔여 프롬프트를 설계
    - 연구3) 가상 주석을 시뮬레이션하여 점 기반 LLM 순위의 일관성과 포괄성을 향상시키는 다측면 기준 앙상블 프레임워크를 제안

- **일부 연구들은 LLM을 사용하여 기존 추천 시스템의 모델 기능을 개선하는 데도 활용**
- LLM과 프롬프트 전략을 사용하여 아이템 관점의 기능을 향상시키기 위해 내용 증대(content augmentation)를 수행
    - 사용자 선호 설명을 생성하기 위한 프롬프트를 설계
    - ChatGPT와 지식 기반을 사용하여 사용자 표현을 향상시키기 위한 추론 그래프를 구성
    - 세 가지 기능 향상 하위 작업을 수행하기 위해 LLM을 활용하는 세 가지 프롬프트를 도입. ChatGPT를 사용하여 초록에 따라 뉴스 제목을 다듬고, 사용자 독서 기록에서 프로필 키워드를 추출

- 순위 모델 외에도 전체 추천 시스템은 일반적으로 콘텐츠 데이터베이스와 후보 검색 모델과 같은 여러 중요한 구성 요소로 구성
- LLM을 추천에 사용하는 또 다른 방법은 전체 시스템의 컨트롤러로 활용
    - LLM 주위에 대화형 추천 프레임워크를 설계하여 사용자의 요구 사항을 다중 턴 대화를 통해 이해
    - 추천 시스템과 데이터베이스, 검색기, 메모리와 같은 다양한 도구를 호출하여 결과를 제공
    - 연구
        - 생성적 추천 프레임워크를 제안하고 AIGC 모델을 사용하여 기존 아이템을 추천할 시기 또는 새로운 아이템을 생성할 시기를 제어하는 데 LLM을 활용
        - LLM을 지능형 시뮬레이터로 활용하여 가상 추천 환경을 개발
            - 시뮬레이터는 일반적으로 사용자와 추천자라는 두 가지 주요 모듈로 구성
            - 사용자 모듈은 추천 사이트를 탐색하고 다른 사용자와 상호작용하며 소셜 미디어에 게시
            - 추천자 모듈은 맞춤형 검색 및 추천 목록을 제공하여 추천을 위한 다양한 모델 디자인을 지원
            - 환경 내의 사용자들은 LLM이 생성한 응답을 기반으로 상호작용하며, 이는 실제 행동을 반영하도록 자연스럽게 진화
        - UniLLMRec : LLM을 활용하여 기억, 순위 지어주기 및 다시 순위 지어주는 작업을 효율적으로 통합하는 종단 간 체인형 추천 프레임워크를 제안

→ 자연어 프롬프트를 사용하여 LLM의 제로샷 능력을 추천 작업에 활용함으로써 비용 효율적이고 실용적인 접근 방식을 제공

**4.1.2 In-context Learning**

- LLM은 몇 개의 시연 입력-레이블 쌍만으로도 추가 매개변수 업데이트 없이 보지 못한 입력에 대한 레이블을 예측 가능
- 연속 추천을 위해
    - 연구1) 입력 상호 작용 시퀀스 자체를 증강하여 시연 예제를 도입
    - 등등
    
    → 실험 결과는 맥락 내 학습 방법이 대부분의 작업에서 LLM의 추천 능력을 향상
    
- 프롬프트 사용과 비교하여, 추천 작업에서 언어 모델(LLMs)의 맥락 내 학습을 탐구한 연구는 소수에 불과

### 4.2 Tuning Paradigm

- LLM은 강력한 제로샷/소수샷 능력 보유
- 그러나, 특정 데이터에 대해 특정 작업을 위해 훈련된 추천 모델의 성능을 초과 불가
- 튜닝 방법의 패러다임을 각각 파인튜닝, 프롬프트 튜닝, 그리고 지시 튜닝의 세 가지 유형으로 분류
- 파인튜닝 패러다임에서는 구별적 및 생성적 대형 언어 모델의 사용 방법이 상당히 유사
    - LLM은 주로 사용자의 혹은 항목의 표현을 추출하는 인코더로 사용됨
    - LLM의 파라미터는 다운스트림 추천 작업의 특정 손실 함수에 따라 파인튜닝
- 프롬프트 튜닝 및 지시 튜닝 패러다임에서는 대형 모델의 출력이 일관된 텍스트 형식을 가지도록, 파라미터는 언어 모델링 손실을 사용하여 훈련
    - 프롬프트 튜닝과 지시 튜닝 훈련 패러다임의 주요 차이점
    - 프롬프트 튜닝이 특정 작업, 예를 들어, 평점 예측에 주로 초점을 맞춤
    - 지시 튜닝 패러다임에서는 LLM이 서로 다른 유형의 지시 아래 여러 작업을 위해 훈련

<aside>
💡

프롬프트 튜닝 vs 지시 튜닝

### **Prompt Tuning (프롬프트 튜닝)**

- **핵심:** 특정 작업에 집중하여 모델을 조정하는 방식.
- **목표:** 한 가지 작업(예: 평점 예측)을 더 잘 수행하도록 모델의 동작을 조정.
- **방법:** 프롬프트(입력의 특정 패턴이나 지침)를 조정하여 원하는 결과를 유도.
- **특징:**
    - 한 가지 작업에 최적화된 방식.
    - 모델의 파라미터는 일반적으로 변경되지 않음(추가 데이터 없이 프롬프트만 변경).
    - **예시:** "사용자가 이 영화를 좋아할 가능성은 몇 점인가요?"라는 특정 질문에 최적화된 학습.

### **Instruction Tuning (지침 튜닝)**

- **핵심:** 여러 작업을 수행할 수 있도록 모델을 훈련하는 방식.
- **목표:** 다양한 작업에서 제로샷(Zero-Shot) 성능을 높이는 것.
- **방법:** 여러 유형의 작업에 대해 다양한 **지침(Instructions)**을 모델에 학습시키고 파라미터를 조정.
- **특징:**
    - 다목적 학습, 여러 작업에 대해 동시에 학습.
    - 새로운 작업도 추가적인 학습 없이 수행 가능(제로샷 성능 향상).
    - **예시:** "이 텍스트를 요약해 주세요", "문장을 번역해 주세요" 등 다양한 작업 수행 가능.
</aside>

**4.2.1 Fine-tuning**

- Discriminative LLM과 근본적으로 유사
- 연구1) GPTRec: GPTRec은 생성적 LLM을 기반으로 하며, 메모리 효율성을 위해 SVD 토큰화를 사용하고, Next-K 생성 전략을 통해 더 유연하게 작동
- 연구2) 사용자의 역사적 상호작용을 프롬프트로 형식화하여, 각 상호작용을 항목에 대한 정보로 표현, 평점 예측 작업을 각각 다중 클래스 분류와 회귀의 두 가지 다른 작업으로 구성
- 등등
- 연구 n) 더 강력한 LLM을 텍스트 인코더로 사용할 경우 추천 정확도가 높아질 수 있음을 발견

**4.2.2 Prompt Tuning**

- LLM은 일반적으로 사용자/항목 정보를 입력으로 받아 항목에 대한 사용자 선호도(예: 좋아요 또는 싫어요, 평점)를 출력하거나 사용자가 관심을 가질 만한 항목을 출력
    - 연구 1) TALLRec: 추천 튜닝을 통해 추가적으로 미세 조정되며, 입력은 사용자의 역사적 시퀀스이고 출력은 "예 또는 아니요" 피드백

**4.2.3 Instruction Tuning** 

이하 생략