# Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search

날짜: 2025년 4월 10일

- [https://arxiv.org/pdf/2412.18319](https://arxiv.org/pdf/2412.18319)
- 집단 몬테 카를로 트리 검색(CoMCTS) 데이터셋을 생성하고
- 생성한 데이터셋으로 지도학습한 모델 Mulberry
- 이 저자들이 Mulberry 데이터셋으로 강화학습한 논문도 3월에 나옴
    - R1-VL: Learning to Reason with Multimodal Large Language Models via Step-wise Group Relative Policy Optimization
    - [https://arxiv.org/pdf/2503.12937](https://arxiv.org/pdf/2503.12937)

## Abstract

- 목표: 최종 답변에 이르기까지 관련된 추론의 각 중간 단계를 생성하는 법을 배워 질문을 이해하고 해결하는 MLLM
- 집단 몬테 카를로 트리 검색(CoMCTS)을 제안
    - 효과적이고 효율적인 추론 경로 검색 및 학습을 위한
    - "트리 검색"에 집단 학습 개념을 도입하는 새로운 학습-추론 방법
    - 네 가지 반복 작업(확장, 시뮬레이션 및 오류 위치 지정, 역전파, 선택)

## 1. Introduction

- **MLLM**
    - 단순한 "직접 예측" 모드에서 주로 작동 (중간 추론 단계를 거의 없이)
    - LLM 추론 잠재력 (예. MCTS와 같은 트리 검색 방법 활용)
    - 직관적인 아이디어는 이러한 “트리 검색” 방법을 직접 적용
        - 한계
        - (1) 검색 효과성: 단일 MLLM의 추론 공간 내에서 동질적인 저품질 노드에 갇혀 결국 낮은 검색 성공률
        - (2) 검색 효율성: 전통적인 MCTS 방법 - 일반적으로 각 검색 반복에서 하나의 후속 추론 노드만을 확장하고 탐색, 매번 단일 단계만 진행하고 대량의 반복을 요구 → 계산 집약적인 MLLM에 비효율적

- **Collective Monte Carlo Tree Search (CoMCTS) 제안**
    - "트리 검색"에 집단 학습 개념을 도입
    - 집단 지식을 활용하여 협력적으로 추측하고, 검색하며, 올바른 답변으로 가는 효과적인 추론 경로를 식별하는 것
        - 효과적인 추론 경로를 반복적으로 검색
        - 각 반복에서, 여러 MLLM의 집단 지식을 활용
        - 공동으로 (a) 주어진 시작 노드에서 끝까지 다양한 후보 후속 추론 노드를 확장
        - (b) 추론 결과를 시뮬레이션, 오류 후보 노드를 위치시키고 그 자식 노드와 함께 가지치기
        - (c) 하향식으로 각 추론 노드의 점수와 방문 횟수를 업데이트
        - (d) 가장 높은 Upper Confidence Bound 값을 가진 잎 추론 노드를 다음 시작 노드로 선택
    - 달성
        - (1) 공동 확장 메커니즘: MLLM 자체의 추론 공간 내에서뿐만 아니라 다른 모델들의 추론 공간에서도 추론 경로 검색을 가능하게 함. (다수 MLLM 사용)
        - (2) 공동 시뮬레이션 및 오류 위치 지정 메커니즘: 각 검색 반복에서 여러 중간 단계를 건너뛰고 마지막 올바른 단계를 다음 시작 노드로 선택. 검색 시간을 크게 줄이면서 검색 효과성을 유지
    - 반사적reflective 추론 경로 검색을 위해 CoMCTS를 확장
        - CoMCTS에 의해 구축된 통합된 추론 트리 → 긍정적 추론 노드, 부정적 추론 노드 모두 제공
        - 부정적인 형제 노드를 효과적인 추론 경로에 통합, 부정적인 추론 노드에서 긍정적인 추론 노드로 전환하는 반사적 추론 경로를 구축
        - 긴 체인 추론 동안 잘못된 노드에서 올바른 노드로 추론 궤적을 동적으로 보정

- **Mulberry-260k**
    - 멀티모달 학습-추론 및 반사 데이터 세트
    - 멀티모달 입력에 대한 효과적이고 반사적인 추론 경로를 검색
    - 각 질문에 대해 풍부하고 명확하며 잘 정의된 추론 노드의 트리 가짐
    - → 집단 감독 세부 조정을 수행
    - → 모델 Mulberry 제안 (단계별 추론 및 반사 능력 MLLM)

- **주요 기여**
    - CoMCTS를 제안:
        - 집단 학습 개념을 MCTS에 도입
        - 반사적인 추론 경로를 공동으로 추측하고, 검색하고, 식별
        - 검색 효과성과 효율성에서 매우 우수
    - Mulberry-260k를 구축
    - Mulberry 모델 개발
    - 다양한 벤치마크에서 우리가 제안한 방법의 우수성을 입증

## 2. Related Works

### 2.1 Multimodal Large Language Model

- **MLLMs**
    - 최근 연구: MLLM 추론 탐구, CoT 프롬프트를 직접 사용하여 최종 답을 도출하는 것이 제한된 이득 또는 오히려 감소를 초래
    - 일부 연구: 계획 기반 CoT 프롬프트를 도입. 모델들이 최종 답을 예측하기 위해 중간 정보를 생성
    - → 본 논문:
        - “트리 서치”의 개념을 MLLM 추론에 처음으로 도입
        - 효과적이고 반사적인 추론 경로를 탐색하는 새로운 CoMCTS 기법을 제안

### 2.2 Large Language Model Reasoning

- **LLM**
    - 3가지 유형: 프롬프트 기반, 계획 기반, 학습 기반 추론
    - 프롬프트 기반 방법: Chain-of-Thought (CoT). 인간의 추론을 모방하기 위해 몇 가지 수작업으로 제작된 단계별 해결책을 참고 자료로 제공
    - 계획 기반 방법: Tree/Graph-of-thought. 트리 또는 그래프 방식으로 여러 추론 경로를 예측. 사려 깊은 의사 결정을 위해 일관된 사고 단위를 사용
    - 학습 기반 추론 방법: 먼저 MCTS와 같은 트리 검색 접근 방식을 사용하여 LLM 자체를 부트스트랩. 중간 사고의 트리를 구축, 효과적인 추론 경로를 탐색 → 경로 활용하여 모델이 단계별로 추론하도록 훈련

### 2.3 Monte-Carlo Tree Search

- 복잡한 의사 결정 문제를 위한 강력한 검색 패러다임
- 다양한 분야에서 폭넓게 탐구
- 본 연구: MLLMs에서 효과적이고 반사적인 추론 경로 검색 및 학습을 가능하게 하는 CoMCTS를 제안한

### 2.4  Collective Learning 집단학습

- 다수의 개인의 집단 지성을 활용하여 학습 결과를 개선하는 것을 목표 (=Co-training)
- 초기: 데이터 부족 문제를 해결하기 위해 집단 지식을 활용
- 최근: 효율적이고 효과적인 딥러닝을 위해 딥 뉴럴 네트워크에서 집단 학습을 도입

## 3. Methodology

- CoMCTS를 제안: “트리 검색”에 집단 학습 개념을 도입
- Mulberry260k 제안: 반성적인 추론 경로 검색을 위한 CoMCTS의 확장 및 CoMCTS를 사용한 데이터 구성
- Mulberry 모델 훈련

### 3.1 CoMCTS for effective reasoning

- **핵심 아이디어:**
    - 집단 지식을 활용하여 협력적으로 추측
    - 효과적인 추론 노드를 반복적으로 탐색하고 식별하여 올바른 답변으로 이어지는 효과적인 추론 경로
    
- 정책 모델 π는 사전 훈련된 MLLM으로 초기화
    - 여러 MLLM 모델들 {π1, π2, ..., πK }의 집합을 이용, 질문(Q)에 대한 효과적인 추론 경로를 함께 찾아 학습
    - Q는 텍스트 작업 지시와 이미지가 결합된 멀티모달 입력
    - 각 모델 π는 주어진 질문에 대해 답을 찾기 위한 중간 추론 상태들을 순차적으로 생성. 추론 상태들은 (s1, s2, s3, ..., sM ) 형태로 모델 π의 파라미터 θ에 의해 결정
    - 각 단계에서 생성되는 중간 추론 상태를 sm
    - 각 추론 단계는 하나 이상의 문장을 포함하며, 문장은 여러 개의 단어 토큰으로 구성

![Image](https://github.com/user-attachments/assets/d20e15e2-dd2f-4570-afe8-3956808e6797)

- **CoMCTS 알고리즘**
    - 루트 노드에서 시작: 응답의 시작 또는 불완전한 응답에서 시작.
    - 특정 수의 반복을 통해 추론 경로 검색을 수행
    - 네 가지 주요 작업으로 구성: (a) 확장, (b) 시뮬레이션 및 오류 위치 지정, (c) 역전파, (d) 선택
        - (a) 확장:
            - 현재 리프 추론 노드를 확장하여 새로운 후속 후보 추론 노드를 통합하는 것
            - 리프 노드 $s_k^m$, 주어진 조건 하에, MLLM의 집합적 지식을 활용하여 다양한 보완 후보 추론 경로 집합을 병렬로 확장
        - (b) 시뮬레이션 및 오류 위치 지정:
            - MLLM이 생성한 집합적 지식을 활용하여 자식 노드의 잠재 가치를 공동으로 추정
            - 낮은 점수 노드를 오류 추론 노드로 간주, 필터링
        - (c) 역전파
            - 작업 a, b에서 집합적 지식 확장, 시뮬레이션, 새로운 추론 트리
            - 리프노드에서 루트노드까지 아래에서 위로 업데이트를 수행
        - (d) 선택
            - 업데이트 된 추론 트리를 순회하며 다음 노드를 선택
            - 탐색과 활용 사이의 균형을 맞추는 Upper Confidence Bound (UCB) 값에 의해 결정
    - 이러한 작업은 미리 정의된 횟수만큼 반복, 올바른 추론 경로가 발견될 때까지 반복
    - → {Q, Y, S} 구성
        - Q (질문): 멀티모달 입력 질문
        - Y (효과적인 추론 경로): 올바른 답변으로 가는 일련의 추론 단계
        - S (추론 트리): 전체 추론 경로를 보여주는 트리 구조
    - → multimodal learning-to-reason data triplet 모음을 구성

### 3.2 reflective reasoning을 위한 CoMCTS

- reflective reasoning 경로 검색을 위해 CoMCTS를 확장
    - 3.1에서 구성한 {Q, Y, S}는 긍정적 및 부정적 추론 노드 모두 제공
    - {Q, Y, S}를 기반으로 부정적 sibling 노드를 식별,
    - 부정적 노드에서 긍정적 추론 노드로의 전환

- **Identifying negative sibling node**
    - UCB를 사용하여 부정적 sibling 추론 노드 식별

- **Constructing reflective reasoning path**
    - 부정적 sibling 노드를 무작위로 샘플링하고 reflection prompt와 연결하여 reflection trajectory를 생성
    - $prompt_{reflect}$: "이전 추론 단계가 잘못되었으므로 다시 생각해 봅시다."와 같은 reflection prompt

### 3.3 Training with Collective MCTS

- Mulberry-260k를 구성: quadruplet 집합  ${{Q, Y, Y_{reflect}, S}} \in D$가 포함된 multimodal learning-to-reason-and-reflect 데이터 세트
    - 두 개의 손실 함수
    - Collective Supervised Fine-Tuning (CoSFT): Q와 Y(효과적 추론 경로) 사이의 로그 확률을 최대화하는 것을 목표
    - CoSFT for reflective reasoning: Yreflect의 로그 확률을 최대화하는 것을 목표

![Image](https://github.com/user-attachments/assets/c75652ba-b29b-4683-bb00-9a19732e4480)

## 4. Experiment

### 4.1 Dataset

- **The Sources of Raw Data**
    - 포괄적이고 일반적인 목적의 추론 데이터셋 구축
    - → 일반 다중 모달 이해, 수학, 그림 이해, 실제 세계 이해, 과학, 의료 이미지 이해 등을 포함한 다양한 도메인

- **Reasoning Data Construction**
    - CoMCTS를 사용하여 궁극적으로 데이터셋인 Mulberry-260K를 구축
    - reflective reasoning training 15K 데이터만 샘플링 (반사 데이터의 과잉 방지)

- **Reasoning Data Distribution**
    - Mulberry-260K에서 CoMCTS가 검색한 추론 경로를 분석
    - 추론 단계가 주로 6에서 8 사이에 위치하며 평균이 7.5
        - Mulberry-260K의 차트 관련 하위 집합: 7에서 10 단계 사이에 크게 위치하며 평균이 9
    - → 유연한 수의 추론 단계로 효과적인 추론 경로를 생성
    - → 모델은 간단한 질문을 처리할 때 “덜 생각하고 더 빨리” 처리, 복잡한 작업을 수행할 때는 “더 많이 생각하고 더 느리게” 처리

### 4.2 Implementation Detail

- CoMCTS에서 집단 학습을 구현, Mulberry-260K를 구성
    - 집단 모델 4개: GPT4o, Qwen2-VL-7B, LLaMA-3.2-11B-Vision-Instruct, Qwen2-VL-72B
    - 최대 검색 반복 횟수를 20으로 설정
    - 하나의 후속 후보 추론 경로를 생성
    - 시뮬레이션 및 오류 위치 지정에서 우리는 임계값 $t$를 0으로 설정
    - 4개 베이스라인(백본)

### 4.3 Main Results

- **베이스라인**: 일반 및 추론 기반 MLLM
- **8개 벤치마크**: 일반 및 수학적 추론, 환각, 시각적 환상, 다학제적 이해 및 추론 등

![Image](https://github.com/user-attachments/assets/2f1ea448-707e-4e19-bba9-6cac8cc5bfa2)

- **Comparison with baselines**
    - 집단 모델에 포함된 모델과 포함되지 않은 모델들 모두 학습
    - → 일반화 입증

- **Comparison with reasoning-response models**
    - SOTA 추론-응답 모델과 Mulberry를 비교
    - → 우수성 입증

- **Comparison with state-of-the-arts**
    - 오픈소스 및 클로즈드 소스 SOTA 모델들과 Mulberry를 비교

### 4.4 Ablation Study

- **Ablation Study on CoMCTS**
    - 각 모델이 전체 트리 검색 성능에 어떻게 기여하는지 분석
    - GPT-4o만 사용하는 CoMCTS는 성능을 63.8%까지만 향상
    - 네 모델을 포함시키면 명백히 가장 좋은 성능(즉, 80.2%)을 발휘 → 집단 학습 효과 검증

![Image](https://github.com/user-attachments/assets/e622d681-60f8-436f-a53b-ca0f23639798)

- **Ablation Study on Mulberry**
    - reflection data를 포함하는 것이 성능을 0.8% 향상

![Image](https://github.com/user-attachments/assets/de3a89ba-bd6c-4022-9654-e4a63379969f)

### 4.5 Discussion

- **Comparison with other tree search method**
    - 기존의 다른 트리 검색 방법들과 검색 효과성과 효율성 면에서 비교
    - 기존의 트리 검색 방법: GPT-4o를 **제한된** 개선으로 향상시키는 것을 관찰
        - 전통적인 MCTS 방법들: 일반적으로 자기 부트스트래핑 방식으로 작동, 종종 단일 MLLM의 추론 공간 내에서 동질적인 저품질 노드에 갇혀버리기 때문
        - CoMCTS:

![Image](https://github.com/user-attachments/assets/582724a3-b5c5-4a30-80ef-cdfa87cdee88)

- **Qualitative comparison**
    - 다른 모델: 철저한 사고 없이 상대적으로 짧은 예측을 생성하여 잘못된 답변
    - Mulberry: 풍부하고 명확하며 잘 정의된 추론 단계를 생성하여 포괄적인 이해

![Image](https://github.com/user-attachments/assets/f1a7bd04-67ca-4420-9cbe-5e79cd21bce9)